{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Syntax natürlicher Sprachen, WS 2023/24\n",
    "\n",
    "# Probeklausur\n",
    "\n",
    "- **Datum: 16.01.2024**\n",
    "- **Bearbeitungszeitraum: 11:30-11:45**\n",
    "- **Abgabetest in Moodle bis 12:00 möglich**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übersicht\n",
    "\n",
    "- [Hinweise zur Bearbeitung](#Hinweise-zur-Bearbeitung)\n",
    "- [Laden von Paketen](#Laden-von-Paketen)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "1. [Konstituenten- und Adjunkttests](#1.-Konstituenten--und-Adjunkttests)\n",
    "\n",
    "---\n",
    "2. [Konstituentengrammatik](#2.-Konstituentengrammatik)\n",
    "3. [X-Bar-Struktur](#3.-X-Bar-Struktur)\n",
    "4. [Parsing-Algorithmen und Rekursionstypen](#4.-Parsing-Algorithmen-und-Rekursionstypen)\n",
    "\n",
    "---\n",
    "5. [Dependenzstruktur](#5.-Dependenzstruktur)\n",
    "6. [Syntaktische Funktion](#6.-Syntaktische-Funktion)\n",
    "7. [Komplexer Satz](#7.-Komplexer-Satz)\n",
    "\n",
    "---\n",
    "8. [Unifikation und Subsumption](#8.-Unifikation-und-Subsumption)\n",
    "9. [Feature-based-Grammar](#9.-Feature-based-Grammar)\n",
    "\n",
    "\n",
    "---\n",
    "10. [Statistisches Parsing](#10.-Statistisches-Parsing)\n",
    "11. [Datengestuetzte Syntaxanalyse](#11.-Datengestuetzte-Syntaxanalyse)\n",
    "12. [Chunk-Analysen](#12.-Chunk-Analysen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hinweise zur Bearbeitung\n",
    "\n",
    "### Falls noch nicht geschehen, benennen Sie bitte zunächst die Datei der Probeklausur-Angabe nach folgendem Schema um: \n",
    "\n",
    " #### `Nachname_Vorname_Matrikelnummer.ipynb`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Hinweise zum Ausfüllen der Codezellen\n",
    "\n",
    "### Wenn gegeben, führen Sie zunächst die mit `#RUN` markierten Codezellen zu Beginn einer Aufgabe aus (dies ist für eine erfolgreiche Bearbeitung der Aufgabe notwendig).\n",
    "\n",
    "### Verändern Sie nur die `#TO_DO`-Codezellen (nur gemäß der Angabe in der jeweiligen Aufgabe)!\n",
    "\n",
    "### Führen Sie `#TO_DO`-Codezellen nach Bearbeitung aus, um das Output ihrer Lösung zu generieren (dieses muss als Teil Ihrer Lösung mit abgespeichert werden); bei aufeinander aufbauenden Aufgaben (`a)`, `b)`usw.) ist zudem  notwendig, dass Sie Ihre Lösung aus der vorangehenden Teilaufgabe ausführen, damit diese in der folgenden zur Verfügung steht.\n",
    "\n",
    "### Angegebene Inhalte (Grammatikregeln usw.) dürfen nicht auskommentiert oder gelöscht werden, außer dies wird explizit anders erwähnt!\n",
    "\n",
    "\n",
    "### WICHTIG: Setzen Sie den Status des Notebooks ggf. auf `Trusted`, damit alle angegebenen Outputs korrekt angezeigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hinweis zur Bewertung\n",
    "\n",
    "### *Jede Teilaufgabe (`#TO_DO`-Codezelle) wird mit 2 Punkten bewertet*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Laden von Paketen\n",
    "\n",
    "### Führen Sie zu Beginn folgende Codezelle aus.\n",
    "\n",
    "### Das erfolgreiche Ausführen dieser ist Voraussetzung für die Bearbeitung der folgenden Aufgaben.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (Führen Sie diese Code-Zelle aus:)\n",
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk import FeatStruct\n",
    "import itertools\n",
    "\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "def transform_nr_conll(sent_nr):\n",
    "    sent_list = []\n",
    "    for line in list(filter(None, sent_nr.split(\"\\n\"))):\n",
    "        line_list = line.split()\n",
    "        line_list.pop(0)\n",
    "        line_list.insert(1,\"_\")\n",
    "        sent_list.append(\" \".join([i for i in line_list[0:]]))\n",
    "\n",
    "    return \"\\n\".join([i for i in sent_list[0:]])\n",
    "\n",
    "\n",
    "\n",
    "from nltk import DependencyGraph\n",
    "from itertools import chain\n",
    "\n",
    "def _tree_labeled(self, i):\n",
    "        node = self.get_by_address(i)\n",
    "        word = node[\"word\"]\n",
    "        rel = node[\"rel\"]        \n",
    "        deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "\n",
    "        if deps:\n",
    "            return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "        else:\n",
    "            return word+'('+rel+')'\n",
    "        \n",
    "def tree_labeled(self):\n",
    "        node = self.root\n",
    "\n",
    "        word = node[\"word\"]\n",
    "        rel = node[\"rel\"]\n",
    "        deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "        return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "\n",
    "DependencyGraph._tree_labeled = _tree_labeled\n",
    "DependencyGraph.tree_labeled = tree_labeled\n",
    "\n",
    "\n",
    "\n",
    "def displacy_dep_input(sent):\n",
    "    deps = []\n",
    "    for dep in sent.split('\\n'):\n",
    "        deps.append(dep.split())\n",
    "\n",
    "    deps = [x for x in deps if x]\n",
    "\n",
    "    ex = []\n",
    "    word_list = []\n",
    "    arc_list = []\n",
    "\n",
    "    for index, dep in enumerate(deps):\n",
    "        word_list.append({\"text\": dep[0], \"tag\": \"\"})\n",
    "        line = index+1\n",
    "        head = int(dep[2])\n",
    "        label = dep[3]\n",
    "        if head>line:\n",
    "            start = index\n",
    "            end = head-1\n",
    "            direction = \"left\"\n",
    "        else:\n",
    "            start = head-1\n",
    "            end = index  \n",
    "            direction = \"right\"\n",
    "        if(label.lower() != \"root\"):\n",
    "            arc_list.append({\"start\": start, \"end\": end, \"label\": label, \"dir\": direction})\n",
    "\n",
    "    ex.append({\n",
    "        \"words\": word_list,\n",
    "        \"arcs\": arc_list\n",
    "    })    \n",
    "\n",
    "    return ex\n",
    "\n",
    "\n",
    "\n",
    "from nltk.featstruct import Feature, UnificationFailure, FeatStructReader\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def check_sanity_constraints(th):\n",
    "    for type1, type2 in itertools.product(th, th):\n",
    "        if type1 in th[type2] and type2 in th[type1]:\n",
    "            if type1 != type2:\n",
    "                raise ValueError(\n",
    "                    \"The type hierarchy is not antisymmetric! \" +\n",
    "                    \"{} subsumes {} and vice versa!\".format(\n",
    "                        type1, type2\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    "def refl_trans_closure(type_hierarchy):\n",
    "    # make everything a set\n",
    "    # and compute reflexive closure\n",
    "    closure = defaultdict(set)\n",
    "    for t in type_hierarchy:\n",
    "        closure[t] = set(type_hierarchy[t])\n",
    "        closure[t].add(t)\n",
    "\n",
    "    # compute transitive closure\n",
    "    still_changes = True\n",
    "    while still_changes:\n",
    "        still_changes = False\n",
    "        for x in closure:\n",
    "            new_for_x = set()\n",
    "            for y in closure[x]:\n",
    "                for z in closure[y]:\n",
    "                    new_for_x.add(z)\n",
    "            len_before = len(closure[x])\n",
    "            closure[x].update(new_for_x)\n",
    "            still_changes |= len(closure[x]) > len_before\n",
    "\n",
    "    return closure\n",
    "\n",
    "\n",
    "class HierarchicalFeature(Feature):\n",
    "    def __init__(self, name, type_hierarchy, **kwargs):\n",
    "        super(HierarchicalFeature, self).__init__(name, **kwargs)\n",
    "\n",
    "        self.hierarchy = refl_trans_closure(type_hierarchy)\n",
    "        check_sanity_constraints(self.hierarchy)\n",
    "\n",
    "    def unify_base_values(self, fval1, fval2, bindings):\n",
    "        candidates = self.hierarchy[fval1].intersection(self.hierarchy[fval2])\n",
    "        score = {t: 0 for t in candidates}\n",
    "        for type1, type2 in itertools.product(candidates, candidates):\n",
    "            if type1 in self.hierarchy[type2]:\n",
    "                score[type1] += 1\n",
    "\n",
    "        return min(candidates, key=score.__getitem__, default=UnificationFailure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 1. Konstituenten- und Adjunkttests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Permutationstest\n",
    "\n",
    "#### Gegeben sei folgender Satz sowie die Permutationen seiner drei Satzglieder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('das', 'ist', 'ein Satz')\n",
      "1 ('das', 'ein Satz', 'ist')\n",
      "2 ('ist', 'das', 'ein Satz')\n",
      "3 ('ist', 'ein Satz', 'das')\n",
      "4 ('ein Satz', 'das', 'ist')\n",
      "5 ('ein Satz', 'ist', 'das')\n"
     ]
    }
   ],
   "source": [
    "#RUN:\n",
    "sentence = [\"das\", \"ist\", \"ein Satz\"]\n",
    "\n",
    "permutations = list(itertools.permutations(sentence))\n",
    "for (i, item) in enumerate(permutations):\n",
    "    print(i, item)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie obenstehende Codezelle aus.\n",
    "\n",
    "\n",
    "### Geben Sie (über den Listenindex) eine Permutation des Satzes an, welche das finite Verb als Konstituente bestätigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "list(itertools.permutations(sentence))[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 Adjunkt-Test\n",
    "\n",
    "#### Gegeben sei folgender Satz, dessen drittes Satzglied den geschehens-Test besteht:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'er wartet, und das geschieht im Park'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\"er\", \"wartet\", \"im Park\"]\n",
    "\n",
    "sentence[0] + \" \" + sentence[1] + \", und das geschieht \" + sentence[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Geben Sie (unter Erhalt der Wohlgeformtheit des Ausgangssatzes) ein alternatives drittes Satzglied an, so dass der geschehens-Test fehlschlägt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'er wartet, und das geschieht auf den Sonnenaufgang'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sentence = [\"er\", \"wartet\", \"auf den Sonnenaufgang\"]\n",
    "\n",
    "sentence[0] + \" \" + sentence[1] + \", und das geschieht \" + sentence[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Konstituentengrammatik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben Sie zu dem folgenden Beispielsatz für temporale syntaktische Ambiguität ein minimale CFG, die die intendierte Struktur des Beispielsatzes erkennt. Testen Sie anschließend Ihre Grammatik (Ausgabe nur der korrekten Analyse).\n",
    "\n",
    "- ***the old man the boat***\n",
    "  - `intendierte Struktur:` *the old (man the boat)VP*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             S              \n",
      "     ┌───────┴───┐           \n",
      "     │           VP         \n",
      "     │       ┌───┴───┐       \n",
      "     NP      │       NP     \n",
      " ┌───┴───┐   │   ┌───┴───┐   \n",
      "DET      N   V  DET      N  \n",
      " │       │   │   │       │   \n",
      "the     old man the     boat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "sentence = \"the old man the boat\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> DET N\n",
    "    VP -> V NP\n",
    "\n",
    "    DET -> \"the\"\n",
    "    N -> \"old\" | \"boat\"\n",
    "    V -> \"man\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. X-Bar-Struktur\n",
    "\n",
    "#### Gegeben sei folgender Satz und eine entsprechende Grammatik:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              S                      \n",
      "     ┌────────┴────┐                  \n",
      "     │             VP                \n",
      "     │        ┌────┴───┐              \n",
      "     NP       │        NP            \n",
      " ┌───┴───┐    │    ┌───┴───────┐      \n",
      "Det      N    V   Det          N     \n",
      " │       │    │    │           │      \n",
      "der     Hund jagt den     Briefträger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"    \n",
    "    N   -> \"Hund\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Erweitern Sie den Satz der Angabe um ein präpositionales Adverbial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"der Hund jagt den Briefträger auf die Straße\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) Erweitern Sie die Grammatik um entsprechende lexikalische und syntaktische Regeln für den erweiterten Satz. Verwenden Sie das X-Bar-Schema, so dass eine **rekursive Adjunktion** von Adverbialen an die VP ermöglicht wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    S                                      \n",
      "     ┌──────────────┴─────────────┐                         \n",
      "     │                            VP                       \n",
      "     │                            │                         \n",
      "     │                          VERBAL                     \n",
      "     │              ┌─────────────┴───────────┐             \n",
      "     │            VERBAL                      PP           \n",
      "     │        ┌─────┴─────┐               ┌───┴───┐         \n",
      "     NP       │           NP              │       NP       \n",
      " ┌───┴───┐    │     ┌─────┴───────┐       │   ┌───┴────┐    \n",
      "Det      N    V    Det            N       P  Det       N   \n",
      " │       │    │     │             │       │   │        │    \n",
      "der     Hund jagt  den       Briefträger auf die     Straße\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"    \n",
    "    N   -> \"Hund\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    VP -> VERBAL\n",
    "    VERBAL -> VERBAL PP\n",
    "    VERBAL -> V NP\n",
    "    PP -> P NP\n",
    "\n",
    "    P -> \"auf\"\n",
    "    Det -> \"die\"\n",
    "    N -> \"Straße\"\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Parsing-Algorithmen und Rekursionstypen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1 Geben Sie CFG-Regeln an, die bei einem Top-Down-Parser wegen Ambiguität zu längerer Laufzeit führen können.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 5 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> Det N\n",
      "    NP -> PROPN\n",
      "    VP -> VP PP\n",
      "    VP -> V NP\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N\n",
    "    NP -> PROPN\n",
    "    VP -> VP PP\n",
    "    VP -> V NP\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.2 Geben Sie CFG-Regeln an, die eine indirekte Rekursion ermöglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 5 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> Det N\n",
      "    VP -> V\n",
      "    VP -> V SBAR\n",
      "    SBAR -> COMP S\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N\n",
    "    VP -> V | V SBAR\n",
    "    SBAR -> COMP S\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Dependenzstruktur\n",
    "\n",
    "## 5.1 Dependenzgrammatik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben Sie zu dem folgenden Beispielsatz für syntaktische Ambiguität eine ungelabelte Dependenzgrammatik gemäß der UD-Dependenzregeln. Testen Sie anschließend Ihre Grammatik (Ausgabe mindestens der beiden möglichen Analysen).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(shot I (elephant an) (pajamas in my)) \n",
      "\n",
      "      shot                  \n",
      " ┌─────┼────────────┐        \n",
      " │  elephant     pajamas    \n",
      " │     │      ┌─────┴─────┐  \n",
      " I     an     in          my\n",
      "\n",
      "(shot I (elephant an (pajamas in my))) \n",
      "\n",
      "        shot                     \n",
      " ┌───────┴──────┐                 \n",
      " │           elephant            \n",
      " │   ┌──────────┴────────┐        \n",
      " │   │                pajamas    \n",
      " │   │          ┌────────┴─────┐  \n",
      " I   an         in             my\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "sentence = \"I shot an elephant in my pajamas\"\n",
    "\n",
    "grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "    'shot' -> 'I' | 'elephant' | 'pajamas'\n",
    "    'elephant' -> 'an' | 'pajamas'\n",
    "    'pajamas' -> 'my' | 'in'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ProjectiveDependencyParser(grammar)\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree, \"\\n\")\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5.2 Übergangsbasierter Shift-Reduce-Dependency-Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betrachten Sie folgende Dependenzanalyse, die die Reihenfolge der Durchführung der `REDUCE`-Übergänge mit einem Shift-Reduce-Dependency-Parser angibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c291b15b95f140ccab2ac5550c084a23-0\" class=\"displacy\" width=\"350\" height=\"187.0\" direction=\"ltr\" style=\"max-width: none; height: 187.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">ich</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">glaube</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">es</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c291b15b95f140ccab2ac5550c084a23-0-0\" stroke-width=\"2px\" d=\"M70,52.0 C70,2.0 150.0,2.0 150.0,52.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c291b15b95f140ccab2ac5550c084a23-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">LEFTARC-1</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,54.0 L62,42.0 78,42.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c291b15b95f140ccab2ac5550c084a23-0-1\" stroke-width=\"2px\" d=\"M170,52.0 C170,2.0 250.0,2.0 250.0,52.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c291b15b95f140ccab2ac5550c084a23-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-2</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250.0,54.0 L258.0,42.0 242.0,42.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_nr = \"\"\"\n",
    "1 ich 2 LEFTARC-1\n",
    "2 glaube 0 ROOT\n",
    "3 es 2 RIGHTARC-2\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gegeben sei nun folgender Dependenzgraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4bd147b81ca348b6bfcfbaf6d829c805-0\" class=\"displacy\" width=\"450\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">b</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">c</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">d</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bd147b81ca348b6bfcfbaf6d829c805-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bd147b81ca348b6bfcfbaf6d829c805-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M145.0,104.0 L153.0,92.0 137.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bd147b81ca348b6bfcfbaf6d829c805-0-1\" stroke-width=\"2px\" d=\"M270,102.0 C270,52.0 345.0,52.0 345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bd147b81ca348b6bfcfbaf6d829c805-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">LEFTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4bd147b81ca348b6bfcfbaf6d829c805-0-2\" stroke-width=\"2px\" d=\"M170,102.0 C170,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4bd147b81ca348b6bfcfbaf6d829c805-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L358.0,92.0 342.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_nr = \"\"\"\n",
    "1 a 0 ROOT\n",
    "2 b 1 RIGHTARC-?\n",
    "3 c 4 LEFTARC-?\n",
    "4 d 2 RIGHTARC-?\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie dem Beispiel entsprechend eine deutschen Satz an, der diese Dependenzstrukturanalyse erfüllt; geben Sie außerdem die Reihenfolge der Durchführung der `REDUCE`-Übergänge mit einem Shift-Reduce-Dependency-Parser an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c230f418389e4227b3edabe790aac674-0\" class=\"displacy\" width=\"450\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Siehe</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">da</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">ein</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">Auto</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c230f418389e4227b3edabe790aac674-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c230f418389e4227b3edabe790aac674-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-3</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M145.0,104.0 L153.0,92.0 137.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c230f418389e4227b3edabe790aac674-0-1\" stroke-width=\"2px\" d=\"M270,102.0 C270,52.0 345.0,52.0 345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c230f418389e4227b3edabe790aac674-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">LEFTARC-1</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c230f418389e4227b3edabe790aac674-0-2\" stroke-width=\"2px\" d=\"M170,102.0 C170,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c230f418389e4227b3edabe790aac674-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-2</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L358.0,92.0 342.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 Siehe 0 ROOT\n",
    "2 da 1 RIGHTARC-3\n",
    "3 ein 4 LEFTARC-1\n",
    "4 Auto 2 RIGHTARC-2\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Syntaktische Funktion\n",
    "\n",
    "### Analysieren Sie die Dependenzbeziehungen des folgenden Satzes im UD-Schema: \n",
    "\n",
    "*der Hund jagt den Briefträger um die Stadt*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               jagt(ROOT)                                \n",
      "     ┌─────────────┼──────────────────────┐               \n",
      "Hund(nsubj) Briefträger(obj)          Stadt(obl)         \n",
      "     │             │            ┌─────────┴─────────┐     \n",
      "  der(det)      den(det)     um(case)            die(det)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"70ea80f491ae46178aae7237c20950c5-0\" class=\"displacy\" width=\"850\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">der</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">Hund</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">jagt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">den</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">Briefträger</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">um</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">die</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Stadt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-70ea80f491ae46178aae7237c20950c5-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,102.0 140.0,102.0 140.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-70ea80f491ae46178aae7237c20950c5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-70ea80f491ae46178aae7237c20950c5-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,102.0 240.0,102.0 240.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-70ea80f491ae46178aae7237c20950c5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-70ea80f491ae46178aae7237c20950c5-0-2\" stroke-width=\"2px\" d=\"M370,152.0 C370,102.0 440.0,102.0 440.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-70ea80f491ae46178aae7237c20950c5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,154.0 L362,142.0 378,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-70ea80f491ae46178aae7237c20950c5-0-3\" stroke-width=\"2px\" d=\"M270,152.0 C270,52.0 445.0,52.0 445.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-70ea80f491ae46178aae7237c20950c5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M445.0,154.0 L453.0,142.0 437.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-70ea80f491ae46178aae7237c20950c5-0-4\" stroke-width=\"2px\" d=\"M570,152.0 C570,52.0 745.0,52.0 745.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-70ea80f491ae46178aae7237c20950c5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570,154.0 L562,142.0 578,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-70ea80f491ae46178aae7237c20950c5-0-5\" stroke-width=\"2px\" d=\"M670,152.0 C670,102.0 740.0,102.0 740.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-70ea80f491ae46178aae7237c20950c5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,154.0 L662,142.0 678,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-70ea80f491ae46178aae7237c20950c5-0-6\" stroke-width=\"2px\" d=\"M270,152.0 C270,2.0 750.0,2.0 750.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-70ea80f491ae46178aae7237c20950c5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,154.0 L758.0,142.0 742.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 der 2 det\n",
    "2 Hund 3 nsubj\n",
    "3 jagt 0 ROOT\n",
    "4 den 5 det\n",
    "5 Briefträger 3 obj\n",
    "6 um 8 case\n",
    "7 die 8 det \n",
    "8 Stadt 3 obl\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Komplexer Satz\n",
    "\n",
    "#### Gegeben sei folgender Satz mit transitivem Verb und eine entsprechende Grammatik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       S                    \n",
      "     ┌─────────────────┴───────┐             \n",
      "     │                         VP           \n",
      "     │                 ┌───────┴────┐        \n",
      "     NP                │            NP      \n",
      " ┌───┴───────┐         │       ┌────┴────┐   \n",
      "Det          N         V      Det        N  \n",
      " │           │         │       │         │   \n",
      "der     Briefträger schreibt einen     Brief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Briefträger schreibt einen Brief\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron\n",
    "\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"    \n",
    "    N   -> \"Hund\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\"\n",
    "    Det -> \"einen\"    \n",
    "    N   -> \"Brief\"\n",
    "    V   -> \"schreibt\"    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a) Ändern Sie den Satz ab, so dass er einen Objekt-Komplementsatz enthält. (Satzzeichen können ausgelassen werden.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"der Briefträger schreibt dass er Hunde mag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b) Erweitern Sie die Grammatik um entsprechende lexikalische und syntaktische Regeln für Ihren Satz aus 8a.\n",
    "\n",
    "\n",
    "- Verwenden Sie nur `SBAR` und `Comp` als neue Nonterminale\n",
    "- X-Bar-Schema ist nicht notwendig (orientieren Sie sich an den Penn-Treebank-Regeln für komplexe Sätze)\n",
    "\n",
    "##### Beachten Sie die invertierte Wortstellung im Nebensatz (Verbendstellung).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              S                          \n",
      "     ┌────────────────────────┴────┐                      \n",
      "     │                             VP                    \n",
      "     │                 ┌───────────┴────┐                 \n",
      "     │                 │               SBAR              \n",
      "     │                 │      ┌─────────┴─────┐           \n",
      "     │                 │      │               S          \n",
      "     │                 │      │    ┌──────────┴────┐      \n",
      "     │                 │      │    │               VP    \n",
      "     │                 │      │    │          ┌────┴───┐  \n",
      "     NP                │      │    NP         NP       │ \n",
      " ┌───┴───────┐         │      │    │          │        │  \n",
      "Det          N         V     Comp Pron        N        V \n",
      " │           │         │      │    │          │        │  \n",
      "der     Briefträger schreibt dass  er       Hunde     mag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron\n",
    "\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"    \n",
    "    N   -> \"Hund\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\"\n",
    "    Det -> \"einen\"    \n",
    "    N   -> \"Brief\"\n",
    "    V   -> \"schreibt\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    VP -> V SBAR\n",
    "    SBAR -> Comp S\n",
    "    VP -> NP V\n",
    "    NP -> N\n",
    "\n",
    "    Comp -> \"dass\"\n",
    "    Pron -> \"er\"\n",
    "    N -> \"Hunde\"\n",
    "    V -> \"mag\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c) Erweitern Sie nun Ihre Grammatik aus 8b) um Merkmale, um eine wortstellungsbezogene Überproduktion im Nebensatz mit der alten VP-Regel für den Hauptsatz zu verhindern.\n",
    "\n",
    "- Nebensatz: Verbendstellung\n",
    "- Hauptsatz: V2-Stelllung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "\n",
    "#NEGATIVBEISPIEL:\n",
    "neg_sentence = \"der Briefträger schreibt dass er mag Hunde\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "########GRAMMATIK AUS 8b):\n",
    "    S[SBAR=?x]   -> NP VP[SBAR=?x]\n",
    "    VP[-SBAR]  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron\n",
    "\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"    \n",
    "    N   -> \"Hund\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\"\n",
    "    Det -> \"einen\"    \n",
    "    N   -> \"Brief\"\n",
    "    V   -> \"schreibt\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    VP -> V SBAR\n",
    "    SBAR -> Comp S[+SBAR]\n",
    "    VP[+SBAR] -> NP V\n",
    "    NP -> N\n",
    "\n",
    "    Comp -> \"dass\"\n",
    "    N -> \"er\" | \"Hunde\"\n",
    "    V -> \"mag\"\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    #tree.pretty_print(unicodelines=True)\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Unifikation und Subsumption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 8.1 Unifikation von Merkmalsstrukturen\n",
    "\n",
    "#### Gegeben seien folgende (unifizierende) Merkmalsstrukturen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ AGR  = [ GEN  = 'mask' ] ]\n",
      "[        [ PERS = 1      ] ]\n",
      "[                          ]\n",
      "[ CASE = 'nom'             ]\n"
     ]
    }
   ],
   "source": [
    "f1 = FeatStruct(\"[CASE=nom,AGR=[GEN=mask, PERS=1]]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie eine alternative Merkmalsstruktur `f2` an, die ***nicht*** mit `f1`unifiziert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "f1 = FeatStruct(\"[CASE=nom,AGR=[GEN=mask, PERS=1]]\")\n",
    "f2 = FeatStruct(\"[CASE=akk]\")\n",
    "print(f1.unify(f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8.2 Unifikation mit Typen\n",
    "\n",
    "#### Gegeben sei folgende Typhierarchie:\n",
    "\n",
    "$$\\bot \\sqsubseteq \\text{Genitiv}$$\n",
    "$$\\bot \\sqsubseteq \\text{nicht-Genitiv}$$\n",
    "$$\\text{nicht-Genitiv} \\sqsubseteq \\text{Nominativ-Akkusativ}$$\n",
    "$$\\text{nicht-Genitiv} \\sqsubseteq \\text{Dativ}$$\n",
    "$$\\text{Nominativ-Akkusativ} \\sqsubseteq \\text{Nominativ}$$\n",
    "$$\\text{Nominativ-Akkusativ} \\sqsubseteq \\text{Akkusativ}$$\n",
    "\n",
    "####  Sie wird (mit abgekürzten Typnamen) durch das `*CASE*`-Feature implementiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN:\n",
    "type_hierarchy = {\n",
    "    \"nichtGen\": [\"NomAkk\", \"Dat\"],\n",
    "    \"NomAkk\": [\"Nom\", \"Akk\"],\n",
    "    \"Dat\": [],\n",
    "    \"Akk\": [],\n",
    "    \"Gen\": [],\n",
    "    \"Nom\": []\n",
    "}\n",
    "CASE = HierarchicalFeature(\"CASE\", type_hierarchy)\n",
    "reader = FeatStructReader(features=(CASE,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie obenstehende Codezelle aus, um die Typhierarchie zu laden.\n",
    "\n",
    "### Geben Sie eine (nicht-leere) Merkmalstruktur `f2` an, sodass gilt:\n",
    "\n",
    "`f2` subsumiert `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "f1 = reader.fromstring(\"[*CASE*=NomAkk]\")\n",
    "f2 = reader.fromstring(\"[*CASE*=nichtGen]\")\n",
    "f2.subsumes(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Feature-based-Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9a) Erweitern Sie folgende Angabe um einen Satz mit intransitivem Verb sowie die Grammatik um entsprechende syntaktische sowie lexikalische Regeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             S            \n",
      "     ┌───────┴────────┐    \n",
      "     NP               VP  \n",
      " ┌───┴───────┐        │    \n",
      "Det          N        V   \n",
      " │           │        │    \n",
      "der     Briefträger wartet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "sentence = \"der Briefträger wartet\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"    \n",
    "    N   -> \"Brief\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"beantwortet\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    VP -> V\n",
    "    V -> \"wartet\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9b) Geben Sie einen nach den Regeln der deutschen Grammatik nicht-wohlgeformten Satz an, der fälschlicherweise von der oben angegebenen Grammatik erkannt wird, obwohl er gegen ein *Subkategorisierungs-Constraint* verstößt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "neg_sentence = \"der Briefträger wartet den Brief\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9c) Erweitern Sie Ihre Grammatik aus a) um Merkmale, um die Überproduktion aus b) zu verhindern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "########GRAMMATIK AUS 9a):\n",
    "    S   -> NP VP\n",
    "    VP  -> V[SUBCAT=0] NP\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"    \n",
    "    N   -> \"Brief\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V[SUBCAT=0]   -> \"beantwortet\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    VP -> V[SUBCAT=1]\n",
    "    V[SUBCAT=1] -> \"wartet\"\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "#NEGATIVBEISPIEL (neg_sentence aus 9b):\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    #tree.pretty_print(unicodelines=True)\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,264.0,168.0\" width=\"264px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S[]</text></svg><svg width=\"60.6061%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP[]</text></svg><svg width=\"35%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Det[]</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">der</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.5%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"65%\" x=\"35%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">N[]</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Briefträger</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.5%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.303%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"39.3939%\" x=\"60.6061%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP[]</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">V[SUBCAT=1]</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">wartet</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80.303%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S[]', [Tree('NP[]', [Tree('Det[]', ['der']), Tree('N[]', ['Briefträger'])]), Tree('VP[]', [Tree('V[SUBCAT=1]', ['wartet'])])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TEST POSITIVBEISPIEL (sentence aus 9a):\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    #tree.pretty_print(unicodelines=True)\n",
    "    display(tree)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Statistisches Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Gegeben sei folgende Mini-Treebank mit PP-Attachment-Sätzen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          S         \n",
      " ┌───┬────┴───┐      \n",
      " │   VP       │     \n",
      " │   │        │      \n",
      " NP  V        PP    \n",
      " │   │    ┌───┼───┐  \n",
      "Ich gehe auf dem Weg\n",
      "\n",
      "            S              \n",
      " ┌──────────┴───┐           \n",
      " │              VP         \n",
      " │    ┌─────────┴───┐       \n",
      " NP   V             PP     \n",
      " │    │     ┌───────┼───┐   \n",
      "Ich steige auf     den Berg\n",
      "\n",
      "              S              \n",
      " ┌────────────┴───┐           \n",
      " │                VP         \n",
      " │     ┌──────────┴───┐       \n",
      " NP    V              PP     \n",
      " │     │      ┌───────┼───┐   \n",
      "Ich klettere auf     den Berg\n",
      "\n",
      "           S         \n",
      " ┌────┬────┴───┐      \n",
      " │    VP       │     \n",
      " │    │        │      \n",
      " NP   V        PP    \n",
      " │    │    ┌───┼───┐  \n",
      "Ich laufe auf dem Weg\n",
      "\n",
      "           S         \n",
      " ┌────┬────┴───┐      \n",
      " │    VP       │     \n",
      " │    │        │      \n",
      " NP   V        PP    \n",
      " │    │    ┌───┼───┐  \n",
      "Ich renne auf dem Weg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treestrings = [\n",
    "\"(S (NP Ich) (VP (V gehe)) (PP auf dem Weg))\",\n",
    "\"(S (NP Ich) (VP (V steige) (PP auf den Berg)))\",\n",
    "\"(S (NP Ich) (VP (V klettere) (PP auf den Berg)))\",\n",
    "\"(S (NP Ich) (VP (V laufe)) (PP auf dem Weg))\",\n",
    "\"(S (NP Ich) (VP (V renne)) (PP auf dem Weg))\",\n",
    "]\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "\n",
    "for tree in trees:\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passen Sie diese Mini-Treebank durch Auskommentieren einer minimalen Anzahl an Sätzen so an, dass die daraus induzierte Grammatik das VP-Attachment (Subkategorisierung nach PP-Komplement statt Satz-Adjunkt) bevorzugt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP [0.5]\n",
      "NP -> 'Ich' [1.0]\n",
      "VP -> V PP [0.5]\n",
      "V -> 'steige' [0.25]\n",
      "PP -> 'auf' 'den' 'Berg' [0.5]\n",
      "V -> 'klettere' [0.25]\n",
      "S -> NP VP PP [0.5]\n",
      "VP -> V [0.5]\n",
      "V -> 'laufe' [0.25]\n",
      "PP -> 'auf' 'dem' 'Weg' [0.5]\n",
      "V -> 'renne' [0.25]\n",
      "(S (NP Ich) (VP (V steige) (PP auf den Berg))) (p=0.03125)\n",
      "            S              \n",
      " ┌──────────┴───┐           \n",
      " │              VP         \n",
      " │    ┌─────────┴───┐       \n",
      " NP   V             PP     \n",
      " │    │     ┌───────┼───┐   \n",
      "Ich steige auf     den Berg\n",
      "\n",
      "(S (NP Ich) (VP (V klettere) (PP auf den Berg))) (p=0.03125)\n",
      "              S              \n",
      " ┌────────────┴───┐           \n",
      " │                VP         \n",
      " │     ┌──────────┴───┐       \n",
      " NP    V              PP     \n",
      " │     │      ┌───────┼───┐   \n",
      "Ich klettere auf     den Berg\n",
      "\n",
      "(S (NP Ich) (VP (V laufe) (PP auf dem Weg))) (p=0.03125)\n",
      "           S             \n",
      " ┌─────────┴───┐          \n",
      " │             VP        \n",
      " │    ┌────────┴───┐      \n",
      " NP   V            PP    \n",
      " │    │    ┌───────┼───┐  \n",
      "Ich laufe auf     dem Weg\n",
      "\n",
      "(S (NP Ich) (VP (V renne) (PP auf dem Weg))) (p=0.03125)\n",
      "           S             \n",
      " ┌─────────┴───┐          \n",
      " │             VP        \n",
      " │    ┌────────┴───┐      \n",
      " NP   V            PP    \n",
      " │    │    ┌───────┼───┐  \n",
      "Ich renne auf     dem Weg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "treestrings = [\n",
    "#\"(S (NP Ich) (VP (V gehe)) (PP auf dem Weg))\",\n",
    "\"(S (NP Ich) (VP (V steige) (PP auf den Berg)))\",\n",
    "\"(S (NP Ich) (VP (V klettere) (PP auf den Berg)))\",\n",
    "\"(S (NP Ich) (VP (V laufe)) (PP auf dem Weg))\",\n",
    "\"(S (NP Ich) (VP (V renne)) (PP auf dem Weg))\",\n",
    "]\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "\n",
    "##print trees in treebank:\n",
    "#for tree in trees:\n",
    "#    tree.pretty_print(unicodelines=True)\n",
    "    \n",
    "    \n",
    "#grammar induction:    \n",
    "productions = []\n",
    "S = nltk.Nonterminal('S')\n",
    "\n",
    "for tree in trees:\n",
    "    productions += tree.productions()\n",
    "\n",
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "for production in grammar.productions():\n",
    "    print(production)    \n",
    "    \n",
    "#parse trees with grammar:    \n",
    "parser = nltk.ViterbiParser(grammar)\n",
    "     \n",
    "for tree in trees:\n",
    "    for parse in parser.parse(tree.leaves()): \n",
    "        print(parse)\n",
    "        parse.pretty_print(unicodelines=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Datengestuetzte Syntaxanalyse\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 11.1 Lexikalisierte CFG (mit Merkmalen)\n",
    "\n",
    "#### Gegeben sei folgende FCFG mit nur teilweise durchgeführter Kopfannotation (über ein `HEAD`-Merkmal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[]\n",
      "  (NP[HEAD='Hund'] (Det[] der) (N[HEAD='Hund'] Hund))\n",
      "  (VP[] (V[] jagt) (NP[HEAD=?n] (Det[] den) (N[] Briefträger))))\n",
      "                                     S[]                               \n",
      "             ┌────────────────────────┴─────┐                           \n",
      "             │                             VP[]                        \n",
      "             │                        ┌─────┴────────┐                  \n",
      "      NP[HEAD='Hund']                 │         NP[HEAD=?n]            \n",
      "  ┌──────────┴──────────────┐         │     ┌────────┴───────────┐      \n",
      "Det[]                 N[HEAD='Hund'] V[]  Det[]                 N[]    \n",
      "  │                         │         │     │                    │      \n",
      " der                       Hund      jagt  den              Briefträger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    VP[]  -> V[] NP[]\n",
    "    NP[HEAD=?n]  -> Det[] N[HEAD=?n]\n",
    "\n",
    "    Det[] -> \"der\"\n",
    "    Det[] -> \"den\"    \n",
    "    N[HEAD=\"Hund\"]   -> \"Hund\"\n",
    "    N[]   -> \"Briefträger\"\n",
    "    V[]   -> \"jagt\"    \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    #display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vervollständigen Sie die Kopfannotation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[HEAD='jagt']\n",
      "  (NP[HEAD='Hund'] (Det[HEAD='der'] der) (N[HEAD='Hund'] Hund))\n",
      "  (VP[HEAD='jagt']\n",
      "    (V[HEAD='jagt'] jagt)\n",
      "    (NP[HEAD='Briefträger']\n",
      "      (Det[HEAD='den'] den)\n",
      "      (N[HEAD='Briefträger'] Briefträger))))\n",
      "                                               S[HEAD='jagt']                                                  \n",
      "                       ┌─────────────────────────────┴───────────────┐                                          \n",
      "                       │                                      VP[HEAD='jagt']                                  \n",
      "                       │                             ┌───────────────┴───────────────┐                          \n",
      "                NP[HEAD='Hund']                      │                        NP[HEAD='Brieftr                 \n",
      "                       │                             │                             äger']                      \n",
      "       ┌───────────────┴──────────────┐              │               ┌───────────────┴────────────────┐         \n",
      "Det[HEAD='der']                 N[HEAD='Hund'] V[HEAD='jagt'] Det[HEAD='den']                  N[HEAD='Briefträ\n",
      "       │                              │              │               │                              ger']      \n",
      "       │                              │              │               │                                │         \n",
      "      der                            Hund           jagt            den                          Briefträger   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[HEAD=?v]   -> NP[] VP[HEAD=?v]\n",
    "    VP[HEAD=?v]  -> V[HEAD=?v] NP[]\n",
    "    NP[HEAD=?n]  -> Det[] N[HEAD=?n]\n",
    "\n",
    "    Det[HEAD=\"der\"] -> \"der\"\n",
    "    Det[HEAD=\"den\"] -> \"den\"    \n",
    "    N[HEAD=\"Hund\"]   -> \"Hund\"\n",
    "    N[HEAD=\"Briefträger\"]   -> \"Briefträger\"\n",
    "    V[HEAD=\"jagt\"]   -> \"jagt\"    \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    #display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 11.2 Parent Annotation (mit Symbolerweiterung)\n",
    "\n",
    "#### Gegeben sei folgende CFG für einen Satz mit transitivem Verb mit unvollständiger *Parent Annotation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 S                         \n",
      "        ┌────────┴─────┐                    \n",
      "        │              VP                  \n",
      "        │        ┌─────┴─────┐              \n",
      "        NP       │           NP            \n",
      "  ┌─────┴───┐    │     ┌─────┴───────┐      \n",
      "Det^NP      N    V   Det^NP          N     \n",
      "  │         │    │     │             │      \n",
      " der       Hund jagt  den       Briefträger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det^NP N\n",
    "\n",
    "    Det^NP -> \"der\"\n",
    "    Det^NP -> \"den\"    \n",
    "    N   -> \"Hund\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\"  \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vervollständigen Sie über Symbolerweiterung (mit `^` als Trennerzeichen) in der CFG die *Parent Annotation*, wie sie durch die Regelanwendungen im Syntaxbaum der Angabe impliziert ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  S                           \n",
      "        ┌─────────┴─────┐                      \n",
      "        │              VP^S                   \n",
      "        │         ┌─────┴──────┐               \n",
      "       NP^S       │          NP^VP            \n",
      "  ┌─────┴────┐    │     ┌──────┴────────┐      \n",
      "Det^NP      N^NP V^VP Det^NP           N^NP   \n",
      "  │          │    │     │               │      \n",
      " der        Hund jagt  den         Briefträger\n",
      "\n",
      "                 S                         \n",
      "        ┌────────┴─────┐                    \n",
      "        │              VP                  \n",
      "        │        ┌─────┴─────┐              \n",
      "        NP       │           NP            \n",
      "  ┌─────┴───┐    │     ┌─────┴───────┐      \n",
      "Det^NP      N    V   Det^NP          N     \n",
      "  │         │    │     │             │      \n",
      " der       Hund jagt  den       Briefträger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det^NP N\n",
    "\n",
    "    Det^NP -> \"der\"\n",
    "    Det^NP -> \"den\"    \n",
    "    N   -> \"Hund\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "  S -> NP^S VP^S\n",
    "  VP^S -> V^VP NP^VP\n",
    "  NP^S -> Det^NP N^NP\n",
    "  NP^VP -> Det^NP N^NP\n",
    "\n",
    "  N^NP -> \"Hund\" | \"Briefträger\"\n",
    "  V^VP -> \"jagt\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Chunk-Analysen\n",
    "\n",
    "### Vervollständigen Sie den die folgende *IOB-Tag-Sequenz* einer NP-Chunk-Analyse erfüllenden deutschen Satz.\n",
    "\n",
    "#### (Beachten Sie auch die gegebenen Satzzeichen bzgl. möglicher Satztypen und entsprechender Worstellung.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B-NP', 'Das'), ('I-NP', 'neue'), ('I-NP', 'Jahr'), ('O', 'bringt'), ('B-NP', 'mir'), ('B-NP', 'viel'), ('I-NP', 'Freude'), ('O', '.')]\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "iob_list = [\n",
    "(\"B-NP\", \"Das\"),\n",
    "(\"I-NP\", \"neue\"),\n",
    "(\"I-NP\", \"Jahr\"),\n",
    "(\"O\", \"bringt\"), \n",
    "(\"B-NP\", \"mir\"),\n",
    "(\"B-NP\", \"viel\"),\n",
    "(\"I-NP\", \"Freude\"),\n",
    "(\"O\", \".\")\n",
    "]\n",
    "\n",
    "print(iob_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
